{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJddn9XkJJDyMhxVb/2Iq8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/radhika3131/Deep_Learning_with_Python/blob/main/ch_07_Intruduction_to_deep_learning_for_computer_vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to convnets\n",
        "\n",
        "The following listing shows what a basic convnet looks like. It's a stack of *Conv* and *MaxPooling2D layers*. You'll see in a minute exactly what they do. We'll build the model using the *Functional API*, which we introduced in the previous chapter."
      ],
      "metadata": {
        "id": "jWSbjNzUtRqA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Installing a small convnet**"
      ],
      "metadata": {
        "id": "oK66cu67tau_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "s0qZvtRUs_kJ"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "inputs = keras.Input(shape=(28, 28, 1))\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x) # this will give output in the form of rant--3 tensors(3D) , now we need to feed this output to a classifer vectors which are 1D such as dense layer .\n",
        "x = layers.Flatten()(x) # So t convert 3d output into 1d we used flatten layer before adding dense layer\n",
        "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " NOTE: a convent takes as input tensors of shape (image height , image width , image channels) , not including batch dimension"
      ],
      "metadata": {
        "id": "YMQFBpjzuTki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQEAeg8mulgf",
        "outputId": "ec74ab40-71cd-46ea-9932-3dc4cd568cec"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 3, 3, 128)         73856     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1152)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                11530     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 104,202\n",
            "Trainable params: 104,202\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can see the output of Conv2D and Maxpooling2D layer is a rank-3 tensor of shape(height , width , channels) . THe width and height are tend to shrink as we gop deper into the model. The numner of channels is controlled by the\\\\first argument passed to the Conv2D(32,64 or 128).\n",
        "after the last Con2D layer , we end up with n output of shape(3,3,128).\n",
        "Next step is to feed output to densly connected vectors .Thes  classifer vectors which are 1D whereas output is rant-3 tensor .So to convert 3d output into 1d we used flatten layer before adding dense layer .\n",
        "\n",
        "Finally we do 10 ways classification so our last layer has 10 outputs and a softmax activation.\n",
        "\n",
        "Now lets train the convnets on MNIST dataset."
      ],
      "metadata": {
        "id": "UsBn2ExuwHdN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training the convnet on MNIST dataset**"
      ],
      "metadata": {
        "id": "_hvrYxRByW8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "test_images = test_images.astype(\"float32\") / 255\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"])\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4kDrQUZunr6",
        "outputId": "5b8b00d3-a4ac-4a1e-f225-255bfa3b72b7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "938/938 [==============================] - 57s 59ms/step - loss: 0.1636 - accuracy: 0.9497\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 54s 57ms/step - loss: 0.0456 - accuracy: 0.9855\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 53s 57ms/step - loss: 0.0308 - accuracy: 0.9906\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 54s 57ms/step - loss: 0.0228 - accuracy: 0.9931\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 53s 57ms/step - loss: 0.0179 - accuracy: 0.9947\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd531ed2b00>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluating the convnt**"
      ],
      "metadata": {
        "id": "gELKwklmGzDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVa3LfhIGsIe",
        "outputId": "b0994515-c8b0-4f5b-ddf5-8074581358f3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0240 - accuracy: 0.9927\n",
            "Test accuracy: 0.993\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6R-uDbu7HA4C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}