{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPzX2NNPsjciadmGmfO96U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/radhika3131/Deep_Learning_with_Python/blob/main/ch_03_Getting_started_with_neural_network_Classification_and_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification and Regression glossary\n",
        "\n",
        "classification and regression involves mnay specialized terms .\n",
        "\n",
        "1. Sample or input- one data point that goes into your model\n",
        "2. Prediction or output - what comes out of you model .\n",
        "3. Target - The truth. what your model should ideally have predicted , according to an external source of data.\n",
        "4. classes - A set of possible labels to chose from in a classification problem .For example , when  classifying cat and dog pictures , \"dog\" and \"cat\" are the two classes.\n",
        "5. Label - A specific instance of class annotation in aclassification problem . For instance , if picture # 1234 is annotated as containing the class \"dog\" the \"dog\" is label of picture #1234\n",
        "6. Griund-Truth or annotations - All targets for a dataset, typically collected by humans.\n",
        "7. Binary Classification - A classification task where each input sample should be categorized into two exclusive categories.\n",
        "8. Multilabel Classification - A classification task where each input samples can be asssigned multiple labels , For instance , a given image may contain both a cat and dog and should be annnotated both with the \"cat\" label and the \"dog\" label .**The number of labels per image is usually varible**.\n",
        "9. Multiclass classification - A classification task where each input sample should be categorized into more than two categories:for instance , classifying handwritten digit.\n",
        "10. Scalar Regression - A task where the target is a  continuous scalar value .Predicting house price is agood example: the different target price from continuous space.\n",
        "11. Vector regression - a task where the target is a set of continuous values .for example , a continuous vector. if you are doing regression against  multiple values(such as coordinates of bounding box in a images.\n",
        "12. Mini- batch or Batch - a small set of samples(typically betwenn 8 and 128)\n",
        "that are processed simultaneously by the model . The number of samples is often a power of 2 , to facilitate the memory allocation of GPU . when training a mini-batch is used to ompute a single gradient descent update applied to the weights of the model\n"
      ],
      "metadata": {
        "id": "mhJDDLVqBgRJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Classifying movie reviews: a binary classification\n",
        "\n",
        "you will learn to classify movie reviews as positive or negative ,based on the content of the movie"
      ],
      "metadata": {
        "id": "iTXaLE7uNlGo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The IMDB dataset\n",
        " you will work work with the IMDB dataset : a set of 50,000 highly polarized reviews from the Internet Movie Database. They are split into 25,000 reviews for training and 25,000 reviews for testing , each set consisting of 50% negative and 50% positive reviews"
      ],
      "metadata": {
        "id": "2j6xPHm6OM3I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the dataset"
      ],
      "metadata": {
        "id": "tEyj6A-aO-j4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nYBqqnYg_WID"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "(train_data , train_labels) , (test_data , test_labels) = imdb.load_data(num_words = 10000)\n",
        "# the argument num_words = 100000 means you will only keep the top 10,000 most frequently occuring words in the training data, this allow us to work work with manageble size"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The variable train__data and test_data are list of reviews ;each review is a list of word indices.train_labels and test_labels are list of 0's and 1's , 0 stand for negatibe and 1 stand for positive"
      ],
      "metadata": {
        "id": "dEu5ci1pRCIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpcj6XUgQ_kP",
        "outputId": "aa28b63e-960e-45be-ab62-832bae2f2f36"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 14,\n",
              " 22,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 973,\n",
              " 1622,\n",
              " 1385,\n",
              " 65,\n",
              " 458,\n",
              " 4468,\n",
              " 66,\n",
              " 3941,\n",
              " 4,\n",
              " 173,\n",
              " 36,\n",
              " 256,\n",
              " 5,\n",
              " 25,\n",
              " 100,\n",
              " 43,\n",
              " 838,\n",
              " 112,\n",
              " 50,\n",
              " 670,\n",
              " 2,\n",
              " 9,\n",
              " 35,\n",
              " 480,\n",
              " 284,\n",
              " 5,\n",
              " 150,\n",
              " 4,\n",
              " 172,\n",
              " 112,\n",
              " 167,\n",
              " 2,\n",
              " 336,\n",
              " 385,\n",
              " 39,\n",
              " 4,\n",
              " 172,\n",
              " 4536,\n",
              " 1111,\n",
              " 17,\n",
              " 546,\n",
              " 38,\n",
              " 13,\n",
              " 447,\n",
              " 4,\n",
              " 192,\n",
              " 50,\n",
              " 16,\n",
              " 6,\n",
              " 147,\n",
              " 2025,\n",
              " 19,\n",
              " 14,\n",
              " 22,\n",
              " 4,\n",
              " 1920,\n",
              " 4613,\n",
              " 469,\n",
              " 4,\n",
              " 22,\n",
              " 71,\n",
              " 87,\n",
              " 12,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 38,\n",
              " 76,\n",
              " 15,\n",
              " 13,\n",
              " 1247,\n",
              " 4,\n",
              " 22,\n",
              " 17,\n",
              " 515,\n",
              " 17,\n",
              " 12,\n",
              " 16,\n",
              " 626,\n",
              " 18,\n",
              " 2,\n",
              " 5,\n",
              " 62,\n",
              " 386,\n",
              " 12,\n",
              " 8,\n",
              " 316,\n",
              " 8,\n",
              " 106,\n",
              " 5,\n",
              " 4,\n",
              " 2223,\n",
              " 5244,\n",
              " 16,\n",
              " 480,\n",
              " 66,\n",
              " 3785,\n",
              " 33,\n",
              " 4,\n",
              " 130,\n",
              " 12,\n",
              " 16,\n",
              " 38,\n",
              " 619,\n",
              " 5,\n",
              " 25,\n",
              " 124,\n",
              " 51,\n",
              " 36,\n",
              " 135,\n",
              " 48,\n",
              " 25,\n",
              " 1415,\n",
              " 33,\n",
              " 6,\n",
              " 22,\n",
              " 12,\n",
              " 215,\n",
              " 28,\n",
              " 77,\n",
              " 52,\n",
              " 5,\n",
              " 14,\n",
              " 407,\n",
              " 16,\n",
              " 82,\n",
              " 2,\n",
              " 8,\n",
              " 4,\n",
              " 107,\n",
              " 117,\n",
              " 5952,\n",
              " 15,\n",
              " 256,\n",
              " 4,\n",
              " 2,\n",
              " 7,\n",
              " 3766,\n",
              " 5,\n",
              " 723,\n",
              " 36,\n",
              " 71,\n",
              " 43,\n",
              " 530,\n",
              " 476,\n",
              " 26,\n",
              " 400,\n",
              " 317,\n",
              " 46,\n",
              " 7,\n",
              " 4,\n",
              " 2,\n",
              " 1029,\n",
              " 13,\n",
              " 104,\n",
              " 88,\n",
              " 4,\n",
              " 381,\n",
              " 15,\n",
              " 297,\n",
              " 98,\n",
              " 32,\n",
              " 2071,\n",
              " 56,\n",
              " 26,\n",
              " 141,\n",
              " 6,\n",
              " 194,\n",
              " 7486,\n",
              " 18,\n",
              " 4,\n",
              " 226,\n",
              " 22,\n",
              " 21,\n",
              " 134,\n",
              " 476,\n",
              " 26,\n",
              " 480,\n",
              " 5,\n",
              " 144,\n",
              " 30,\n",
              " 5535,\n",
              " 18,\n",
              " 51,\n",
              " 36,\n",
              " 28,\n",
              " 224,\n",
              " 92,\n",
              " 25,\n",
              " 104,\n",
              " 4,\n",
              " 226,\n",
              " 65,\n",
              " 16,\n",
              " 38,\n",
              " 1334,\n",
              " 88,\n",
              " 12,\n",
              " 16,\n",
              " 283,\n",
              " 5,\n",
              " 16,\n",
              " 4472,\n",
              " 113,\n",
              " 103,\n",
              " 32,\n",
              " 15,\n",
              " 16,\n",
              " 5345,\n",
              " 19,\n",
              " 178,\n",
              " 32]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2Y-3rrfRZtW",
        "outputId": "2cd99c0c-db99-443d-b268-d8c306477e73"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# as we are restricting ourselves on the top 10,000 nost frequent words , no word index will exceed 10,000\n",
        "max([max(sequence) for sequence in train_data]) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srF6gkXrRe8N",
        "outputId": "b7d1bf2b-c607-4e20-a93b-6be5c3b96d7a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9999"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decoding reviews back to english word(text)"
      ],
      "metadata": {
        "id": "ws6bhcwCSFIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = imdb.get_word_index() # word_index is a dictionary mapping words to an integer index\n",
        "reverse_word_index = dict(\n",
        "    [(value, key) for (key , value ) in word_index.items()]# reverse it map integer indexes to a word \n",
        ")\n",
        "\n",
        "decode_review = \" \".join(\n",
        "    [reverse_word_index.get(i - 3 , \"?\") for i in train_data[0]]\n",
        ")\n",
        "# decode the review ,Note that the indices are offset by 3 becz 0 and 1 and 2 are reserved indices for \"padding\" , \"start of sequence \" and \"unknown\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yltaSgeuR1fa",
        "outputId": "6771b5e9-904c-42a8-805a-35e20ccb077d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1641221/1641221 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-OLYZWRqV6pv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}