{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/radhika3131/Deep_Learning_with_Python/blob/main/ch_04_Fundamentals_of_Machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaBUzbzUgeOy"
      },
      "source": [
        "# Generalization : The goal of machine Learning\n",
        "\n",
        "Te fundamental issue in machine learning is the tenaion between optimization and generalization . **Optimization** refers to the process of adjusting a model to get the best performance possible on training data(The learning in machine learning)\n",
        "\n",
        "**Generalization** refers to how well trained model performs on data it has never seen before."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Rb2PRjziKLf"
      },
      "source": [
        "#Underfitting and Overfitting\n",
        "\n",
        "at the beginning of training , optimization and generalization are correlated , lower the loss on training data , the lower the loss on test data , while this is happening your model is **underfit**.\n",
        "\n",
        "**overfitting** - when we get better accuracy on training data but less on testing data.\n",
        "\n",
        "overfitting likely to occur when your data is noisy, if it involves uncertainity , or it includes rare features\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeuDG0gnvAGW"
      },
      "source": [
        "**Adding white noise channels or all zeros channels to MNIST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElyTev4agjyN",
        "outputId": "3bc0775b-ec69-41cd-ad61-37199ada4467"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "(train_images, train_labels), _ = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "\n",
        "train_images_with_noise_channels = np.concatenate(\n",
        "    [train_images, np.random.random((len(train_images), 784))], axis=1)\n",
        "\n",
        "train_images_with_zeros_channels = np.concatenate(\n",
        "    [train_images, np.zeros((len(train_images), 784))], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nL4_Zk5bvnfc"
      },
      "source": [
        "**Training the same model on MNIST data with noise channels or all-zeros channels**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baa77L1DvmKk",
        "outputId": "cd3de6de-5390-406d-b82a-703224b28ed4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "375/375 [==============================] - 10s 24ms/step - loss: 0.6151 - accuracy: 0.8119 - val_loss: 0.2809 - val_accuracy: 0.9161\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 14s 36ms/step - loss: 0.2516 - accuracy: 0.9222 - val_loss: 0.1985 - val_accuracy: 0.9406\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 13s 34ms/step - loss: 0.1664 - accuracy: 0.9482 - val_loss: 0.2701 - val_accuracy: 0.9122\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 8s 22ms/step - loss: 0.1171 - accuracy: 0.9632 - val_loss: 0.1600 - val_accuracy: 0.9526\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 7s 20ms/step - loss: 0.0877 - accuracy: 0.9730 - val_loss: 0.1218 - val_accuracy: 0.9665\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 8s 22ms/step - loss: 0.0653 - accuracy: 0.9792 - val_loss: 0.1212 - val_accuracy: 0.9649\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.0478 - accuracy: 0.9851 - val_loss: 0.1398 - val_accuracy: 0.9608\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 8s 22ms/step - loss: 0.0354 - accuracy: 0.9886 - val_loss: 0.1399 - val_accuracy: 0.9607\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 8s 22ms/step - loss: 0.0250 - accuracy: 0.9924 - val_loss: 0.1365 - val_accuracy: 0.9657\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 7s 20ms/step - loss: 0.0187 - accuracy: 0.9941 - val_loss: 0.1319 - val_accuracy: 0.9690\n",
            "Epoch 1/10\n",
            "375/375 [==============================] - 8s 20ms/step - loss: 0.2959 - accuracy: 0.9155 - val_loss: 0.1605 - val_accuracy: 0.9518\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 8s 22ms/step - loss: 0.1235 - accuracy: 0.9647 - val_loss: 0.1129 - val_accuracy: 0.9669\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 8s 22ms/step - loss: 0.0820 - accuracy: 0.9758 - val_loss: 0.0898 - val_accuracy: 0.9729\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 7s 20ms/step - loss: 0.0598 - accuracy: 0.9826 - val_loss: 0.0813 - val_accuracy: 0.9745\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 8s 22ms/step - loss: 0.0442 - accuracy: 0.9869 - val_loss: 0.0764 - val_accuracy: 0.9781\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 7s 19ms/step - loss: 0.0338 - accuracy: 0.9903 - val_loss: 0.0730 - val_accuracy: 0.9783\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 8s 22ms/step - loss: 0.0253 - accuracy: 0.9930 - val_loss: 0.0695 - val_accuracy: 0.9794\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 8s 21ms/step - loss: 0.0192 - accuracy: 0.9945 - val_loss: 0.0740 - val_accuracy: 0.9794\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 7s 20ms/step - loss: 0.0142 - accuracy: 0.9960 - val_loss: 0.0722 - val_accuracy: 0.9793\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 8s 22ms/step - loss: 0.0105 - accuracy: 0.9974 - val_loss: 0.0716 - val_accuracy: 0.9808\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def get_model():\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(512, activation=\"relu\"),\n",
        "        layers.Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "    model.compile(optimizer=\"rmsprop\",\n",
        "                  loss=\"sparse_categorical_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "model = get_model()\n",
        "history_noise = model.fit(\n",
        "    train_images_with_noise_channels, train_labels,\n",
        "    epochs=10,\n",
        "    batch_size=128,\n",
        "    validation_split=0.2)\n",
        "\n",
        "model = get_model()\n",
        "history_zeros = model.fit(\n",
        "    train_images_with_zeros_channels, train_labels,\n",
        "    epochs=10,\n",
        "    batch_size=128,\n",
        "    validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXdyg3iAwJM4"
      },
      "source": [
        "**Plotting a validation accuracy comparision**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "M63HqMl0v-kn",
        "outputId": "c6d5ba0d-e084-4939-d29d-6d3710046a55"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fdeb02756a0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "val_acc_noise = history_noise.history[\"val_accuracy\"]\n",
        "val_acc_zeros = history_zeros.history[\"val_accuracy\"]\n",
        "epochs = range(1, 11)\n",
        "plt.plot(epochs, val_acc_noise, \"b-\",\n",
        "         label=\"Validation accuracy with noise channels\")\n",
        "plt.plot(epochs, val_acc_zeros, \"b--\",\n",
        "         label=\"Validation accuracy with zeros channels\")\n",
        "plt.title(\"Effect of noise channels on validation accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGxPOlJOxU3Y"
      },
      "source": [
        "Despite the data holding the same information in both cases , the validation accuracy of the model trained with noise channels ends up about one percentage point lower , purely through the influence of spurious correlation . The more noise channels you add , the further accuracy will degrade."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbK3l2PVyDkg"
      },
      "source": [
        "#The nature of generalization in Deep Learning\n",
        "\n",
        "The remarkable fact about deep learning model is that they can be trained to fit anything , as long as they enough representational power \n",
        "\n",
        "Try shuffling the MNISt labels and train a model on that.Even though there is no relationship whatsoever between the inputs and the shuffled labels , the training loss goes down just fine , even with a relatively small model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNA4XX5XzXt_"
      },
      "source": [
        "**Fitting a MNIST model with randomly shuffled labels**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOVY1bQCx4_O",
        "outputId": "69b7eacb-0d8d-4c1d-c8b1-e3f5013a6c68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "375/375 [==============================] - 5s 11ms/step - loss: 2.3158 - accuracy: 0.1030 - val_loss: 2.3055 - val_accuracy: 0.1085\n",
            "Epoch 2/100\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 2.2992 - accuracy: 0.1191 - val_loss: 2.3090 - val_accuracy: 0.1048\n",
            "Epoch 3/100\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.2918 - accuracy: 0.1246 - val_loss: 2.3148 - val_accuracy: 0.1030\n",
            "Epoch 4/100\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.2802 - accuracy: 0.1370 - val_loss: 2.3206 - val_accuracy: 0.1013\n",
            "Epoch 5/100\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 2.2645 - accuracy: 0.1516 - val_loss: 2.3313 - val_accuracy: 0.1079\n",
            "Epoch 6/100\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.2456 - accuracy: 0.1661 - val_loss: 2.3459 - val_accuracy: 0.1028\n",
            "Epoch 7/100\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.2232 - accuracy: 0.1795 - val_loss: 2.3525 - val_accuracy: 0.1032\n",
            "Epoch 8/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 2.1960 - accuracy: 0.1950 - val_loss: 2.3693 - val_accuracy: 0.1006\n",
            "Epoch 9/100\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.1670 - accuracy: 0.2108 - val_loss: 2.3887 - val_accuracy: 0.1020\n",
            "Epoch 10/100\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.1358 - accuracy: 0.2262 - val_loss: 2.4160 - val_accuracy: 0.0975\n",
            "Epoch 11/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 2.1006 - accuracy: 0.2435 - val_loss: 2.4373 - val_accuracy: 0.1019\n",
            "Epoch 12/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 2.0637 - accuracy: 0.2634 - val_loss: 2.4777 - val_accuracy: 0.0995\n",
            "Epoch 13/100\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.0268 - accuracy: 0.2813 - val_loss: 2.4902 - val_accuracy: 0.1012\n",
            "Epoch 14/100\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 1.9867 - accuracy: 0.2959 - val_loss: 2.5162 - val_accuracy: 0.1055\n",
            "Epoch 15/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 1.9476 - accuracy: 0.3131 - val_loss: 2.5548 - val_accuracy: 0.1038\n",
            "Epoch 16/100\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 1.9078 - accuracy: 0.3294 - val_loss: 2.5709 - val_accuracy: 0.1032\n",
            "Epoch 17/100\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 1.8683 - accuracy: 0.3448 - val_loss: 2.6041 - val_accuracy: 0.1030\n",
            "Epoch 18/100\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 1.8267 - accuracy: 0.3645 - val_loss: 2.6557 - val_accuracy: 0.1045\n",
            "Epoch 19/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 1.7886 - accuracy: 0.3780 - val_loss: 2.6809 - val_accuracy: 0.1066\n",
            "Epoch 20/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 1.7495 - accuracy: 0.3943 - val_loss: 2.7245 - val_accuracy: 0.0994\n",
            "Epoch 21/100\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 1.7111 - accuracy: 0.4086 - val_loss: 2.7549 - val_accuracy: 0.1025\n",
            "Epoch 22/100\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 1.6727 - accuracy: 0.4226 - val_loss: 2.8100 - val_accuracy: 0.1015\n",
            "Epoch 23/100\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 1.6352 - accuracy: 0.4368 - val_loss: 2.8402 - val_accuracy: 0.1050\n",
            "Epoch 24/100\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 1.6000 - accuracy: 0.4505 - val_loss: 2.9059 - val_accuracy: 0.1007\n",
            "Epoch 25/100\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 1.5646 - accuracy: 0.4641 - val_loss: 2.9410 - val_accuracy: 0.1059\n",
            "Epoch 26/100\n",
            "375/375 [==============================] - 5s 15ms/step - loss: 1.5309 - accuracy: 0.4766 - val_loss: 2.9936 - val_accuracy: 0.1013\n",
            "Epoch 27/100\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 1.4962 - accuracy: 0.4898 - val_loss: 3.0256 - val_accuracy: 0.1047\n",
            "Epoch 28/100\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 1.4641 - accuracy: 0.5020 - val_loss: 3.0748 - val_accuracy: 0.0978\n",
            "Epoch 29/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 1.4295 - accuracy: 0.5130 - val_loss: 3.1304 - val_accuracy: 0.1047\n",
            "Epoch 30/100\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 1.4006 - accuracy: 0.5244 - val_loss: 3.1845 - val_accuracy: 0.1015\n",
            "Epoch 31/100\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 1.3674 - accuracy: 0.5368 - val_loss: 3.2393 - val_accuracy: 0.1014\n",
            "Epoch 32/100\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 1.3365 - accuracy: 0.5487 - val_loss: 3.3064 - val_accuracy: 0.1003\n",
            "Epoch 33/100\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 1.3085 - accuracy: 0.5584 - val_loss: 3.3417 - val_accuracy: 0.1022\n",
            "Epoch 34/100\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 1.2794 - accuracy: 0.5717 - val_loss: 3.3854 - val_accuracy: 0.0987\n",
            "Epoch 35/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 1.2506 - accuracy: 0.5825 - val_loss: 3.4413 - val_accuracy: 0.1009\n",
            "Epoch 36/100\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 1.2243 - accuracy: 0.5900 - val_loss: 3.4824 - val_accuracy: 0.1054\n",
            "Epoch 37/100\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 1.1985 - accuracy: 0.5984 - val_loss: 3.5537 - val_accuracy: 0.1063\n",
            "Epoch 38/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 1.1710 - accuracy: 0.6092 - val_loss: 3.6026 - val_accuracy: 0.1014\n",
            "Epoch 39/100\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 1.1443 - accuracy: 0.6176 - val_loss: 3.7018 - val_accuracy: 0.1033\n",
            "Epoch 40/100\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 1.1224 - accuracy: 0.6240 - val_loss: 3.7385 - val_accuracy: 0.1040\n",
            "Epoch 41/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 1.0983 - accuracy: 0.6354 - val_loss: 3.7926 - val_accuracy: 0.1028\n",
            "Epoch 42/100\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 1.0736 - accuracy: 0.6433 - val_loss: 3.8628 - val_accuracy: 0.1038\n",
            "Epoch 43/100\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 1.0513 - accuracy: 0.6496 - val_loss: 3.9308 - val_accuracy: 0.0993\n",
            "Epoch 44/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 1.0274 - accuracy: 0.6607 - val_loss: 3.9549 - val_accuracy: 0.1036\n",
            "Epoch 45/100\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 1.0054 - accuracy: 0.6680 - val_loss: 4.0306 - val_accuracy: 0.1033\n",
            "Epoch 46/100\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.9856 - accuracy: 0.6737 - val_loss: 4.1012 - val_accuracy: 0.1053\n",
            "Epoch 47/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.9664 - accuracy: 0.6824 - val_loss: 4.1549 - val_accuracy: 0.1020\n",
            "Epoch 48/100\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.9441 - accuracy: 0.6892 - val_loss: 4.2048 - val_accuracy: 0.1030\n",
            "Epoch 49/100\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.9252 - accuracy: 0.6966 - val_loss: 4.2905 - val_accuracy: 0.0989\n",
            "Epoch 50/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.9054 - accuracy: 0.7024 - val_loss: 4.3524 - val_accuracy: 0.1028\n",
            "Epoch 51/100\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.8847 - accuracy: 0.7087 - val_loss: 4.4290 - val_accuracy: 0.1008\n",
            "Epoch 52/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.8687 - accuracy: 0.7164 - val_loss: 4.4821 - val_accuracy: 0.1035\n",
            "Epoch 53/100\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.8496 - accuracy: 0.7229 - val_loss: 4.5246 - val_accuracy: 0.1053\n",
            "Epoch 54/100\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.8329 - accuracy: 0.7281 - val_loss: 4.6536 - val_accuracy: 0.1042\n",
            "Epoch 55/100\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.8130 - accuracy: 0.7360 - val_loss: 4.6881 - val_accuracy: 0.0979\n",
            "Epoch 56/100\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.8005 - accuracy: 0.7371 - val_loss: 4.7356 - val_accuracy: 0.0979\n",
            "Epoch 57/100\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.7832 - accuracy: 0.7448 - val_loss: 4.8151 - val_accuracy: 0.0999\n",
            "Epoch 58/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.7652 - accuracy: 0.7514 - val_loss: 4.8894 - val_accuracy: 0.0993\n",
            "Epoch 59/100\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.7506 - accuracy: 0.7544 - val_loss: 4.9587 - val_accuracy: 0.0983\n",
            "Epoch 60/100\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.7330 - accuracy: 0.7634 - val_loss: 4.9983 - val_accuracy: 0.1035\n",
            "Epoch 61/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.7200 - accuracy: 0.7672 - val_loss: 5.0767 - val_accuracy: 0.0997\n",
            "Epoch 62/100\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.7080 - accuracy: 0.7724 - val_loss: 5.1666 - val_accuracy: 0.1022\n",
            "Epoch 63/100\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.6910 - accuracy: 0.7760 - val_loss: 5.2273 - val_accuracy: 0.0987\n",
            "Epoch 64/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.6789 - accuracy: 0.7829 - val_loss: 5.3251 - val_accuracy: 0.0978\n",
            "Epoch 65/100\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.6650 - accuracy: 0.7854 - val_loss: 5.3916 - val_accuracy: 0.1013\n",
            "Epoch 66/100\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.6517 - accuracy: 0.7903 - val_loss: 5.4415 - val_accuracy: 0.0967\n",
            "Epoch 67/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.6371 - accuracy: 0.7950 - val_loss: 5.5421 - val_accuracy: 0.1024\n",
            "Epoch 68/100\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.6276 - accuracy: 0.7990 - val_loss: 5.5797 - val_accuracy: 0.1013\n",
            "Epoch 69/100\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.6147 - accuracy: 0.8016 - val_loss: 5.6758 - val_accuracy: 0.1006\n",
            "Epoch 70/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.5994 - accuracy: 0.8089 - val_loss: 5.7377 - val_accuracy: 0.1002\n",
            "Epoch 71/100\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 0.5886 - accuracy: 0.8120 - val_loss: 5.7741 - val_accuracy: 0.1036\n",
            "Epoch 72/100\n",
            "375/375 [==============================] - 6s 15ms/step - loss: 0.5786 - accuracy: 0.8152 - val_loss: 5.8513 - val_accuracy: 0.0988\n",
            "Epoch 73/100\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.5642 - accuracy: 0.8215 - val_loss: 5.9834 - val_accuracy: 0.0976\n",
            "Epoch 74/100\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.5544 - accuracy: 0.8254 - val_loss: 6.0101 - val_accuracy: 0.1010\n",
            "Epoch 75/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.5447 - accuracy: 0.8271 - val_loss: 6.0509 - val_accuracy: 0.0974\n",
            "Epoch 76/100\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.5332 - accuracy: 0.8303 - val_loss: 6.1427 - val_accuracy: 0.0987\n",
            "Epoch 77/100\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.5228 - accuracy: 0.8343 - val_loss: 6.2896 - val_accuracy: 0.1037\n",
            "Epoch 78/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.5112 - accuracy: 0.8393 - val_loss: 6.3796 - val_accuracy: 0.1030\n",
            "Epoch 79/100\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.5040 - accuracy: 0.8420 - val_loss: 6.3575 - val_accuracy: 0.0993\n",
            "Epoch 80/100\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.4936 - accuracy: 0.8446 - val_loss: 6.4348 - val_accuracy: 0.0994\n",
            "Epoch 81/100\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 0.4847 - accuracy: 0.8484 - val_loss: 6.5122 - val_accuracy: 0.1007\n",
            "Epoch 82/100\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.4775 - accuracy: 0.8499 - val_loss: 6.6210 - val_accuracy: 0.1013\n",
            "Epoch 83/100\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.4675 - accuracy: 0.8539 - val_loss: 6.6483 - val_accuracy: 0.1015\n",
            "Epoch 84/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.4568 - accuracy: 0.8567 - val_loss: 6.7469 - val_accuracy: 0.1007\n",
            "Epoch 85/100\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.4483 - accuracy: 0.8597 - val_loss: 6.8090 - val_accuracy: 0.1031\n",
            "Epoch 86/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.4386 - accuracy: 0.8625 - val_loss: 6.8716 - val_accuracy: 0.1041\n",
            "Epoch 87/100\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.4324 - accuracy: 0.8647 - val_loss: 6.9366 - val_accuracy: 0.1050\n",
            "Epoch 88/100\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.4249 - accuracy: 0.8666 - val_loss: 6.9794 - val_accuracy: 0.0977\n",
            "Epoch 89/100\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 0.4135 - accuracy: 0.8715 - val_loss: 7.1160 - val_accuracy: 0.1013\n",
            "Epoch 90/100\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.4094 - accuracy: 0.8728 - val_loss: 7.1427 - val_accuracy: 0.1047\n",
            "Epoch 91/100\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.4000 - accuracy: 0.8766 - val_loss: 7.2743 - val_accuracy: 0.1013\n",
            "Epoch 92/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.3935 - accuracy: 0.8790 - val_loss: 7.3026 - val_accuracy: 0.0995\n",
            "Epoch 93/100\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.3845 - accuracy: 0.8820 - val_loss: 7.3466 - val_accuracy: 0.1003\n",
            "Epoch 94/100\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.3787 - accuracy: 0.8841 - val_loss: 7.5064 - val_accuracy: 0.1005\n",
            "Epoch 95/100\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 0.3727 - accuracy: 0.8859 - val_loss: 7.5280 - val_accuracy: 0.0995\n",
            "Epoch 96/100\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.3622 - accuracy: 0.8897 - val_loss: 7.6300 - val_accuracy: 0.1034\n",
            "Epoch 97/100\n",
            "375/375 [==============================] - 4s 12ms/step - loss: 0.3571 - accuracy: 0.8908 - val_loss: 7.6863 - val_accuracy: 0.1032\n",
            "Epoch 98/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.3520 - accuracy: 0.8924 - val_loss: 7.8204 - val_accuracy: 0.1001\n",
            "Epoch 99/100\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.3465 - accuracy: 0.8934 - val_loss: 7.8272 - val_accuracy: 0.1047\n",
            "Epoch 100/100\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.3391 - accuracy: 0.8960 - val_loss: 7.9194 - val_accuracy: 0.1034\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdeb00f9430>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "(train_images, train_labels), _ = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "\n",
        "random_train_labels = train_labels[:]\n",
        "np.random.shuffle(random_train_labels)\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(train_images, random_train_labels,\n",
        "          epochs=100,\n",
        "          batch_size=128,\n",
        "          validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The manifold hypothesis**\n",
        "\n",
        "**Interpolation as a source of generalization**\n",
        "\n",
        "**Why deep learning works**\n",
        "\n",
        "A deep learning model is basically a very high-dimensional curve-a curve that is smooth and continuous (with additional constraints on its structure, originating from model architecture priors), since it needs to be differentiable. And that curve is fitted to data points via gradient descent, smoothly and incrementally. By its very nature, deep learning is about taking a big, complex curve-a manifold-and incrementally adjusting its parameters until it fits some training data points.\n",
        "\n",
        "\n",
        "The curve involves enough parameters that it could fit anythingindeed, if you let your model train for long enough, it will effectively end up purely memorizing its training data and won't generalize at all. However, the data you're fitting to isn't made of isolated points sparsely distributed across the underlying space. Your data forms a highly structured, low-dimensional manifold within the input space-that's the mani- fold hypothesis. And because fitting your model curve to this data happens gradually and smoothly over time as gradient descent progresses, there will be an intermediate point during training at which the model roughly approximates the natural manifold of the data,\n",
        "\n",
        "**Training data is paramount**\n",
        "\n",
        "#Evaluating machine-learning models\n",
        "\n",
        "**Training, validation, and test sets**\n",
        "\n",
        "Evaluating a model always boils down to splitting the available data into three sets: training, validation, and test. You train on the training data and evaluate your model on the validation data. Once your model is ready for prime time, you test it one final time on the test data, which is meant to be as similar as possible to production data. Then you can deploy the model in production.\n",
        "\n",
        "You y ask, why not have two sets: a training set and a test set? You'd train on the may training data and evaluate on the test data. Much simpler!\n",
        "\n",
        "The reason is that developing a model always involves tuning its configuration: for example, choosing the number of layers or the size of the layers (called the hyperpa- rameters of the model, to distinguish them from the parameters, which are the network's weights). You do this tuning by using as a feedback signal the performance of the model on the validation data. In essence, this tuning is a form of learning a search for a good configuration in some parameter space. As a result, tuning the configuration of the model based on its performance on the validation set can quickly result in over-\n",
        "\n",
        "fitting to the validation set, even though your model is never directly trained on it\n",
        "\n",
        "Central to this phenomenon is the notion of information leaks. Every time you tune a hyperparameter of your model based on the model's performance on the validation set, some information about the validation data leaks into the model. If you do this only once, for one parameter, then very few bits of information will leak, and your val idation set will remain reliable for evaluating the model. But if you repeat this many times-running one experiment, evaluating on the validation set, and modifying your model as a result-then you'll leak an increasingly significant amount of information about the cation set into the model.\n",
        "\n",
        "At the end the day, you'll end up with a model that performs artificially well on the wild because that's what you optimized it for. You care about perfor mance on couge new data, not on the validation data, so you need to use a com pletely different, never-before-seen dataset to evaluate the model: the test dataset Your model shouldn't have had access to any information about the test set, even indi- rectly. If anything about the model has been tuned based on test set performance, then your measure of generalization will be flawed.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Splitting your data into training, validation, and test sets may seem but there are a few advanced ways to do it that can come in handy when little data is available. Let's review three classic evaluation :\n",
        "\n",
        "**Simple hold-out validation**\n",
        "\n",
        "Set apart some fraction of your data as your test set. Train on the remaining data, and evaluate on the test set. As you saw in the previous sections, in order to prevent infor mation leaks, you shouldn't tune your model based on the test set, and therefore you should also reserve a validation set.\n",
        "\n",
        "This is the simplest evaluation protocol, and it suffers from one flaw: if little data is available, then your validation and test sets may contain too few samples to be statisti- cally representative of the data at hand. This is easy to recognize: if different random shuffling rounds of the data before splitting end up yielding very different measures of model performance, then you're having this issue. K-fold validation and iterated K-fold validation are two ways to address this, as discussed next.\n",
        "\n",
        "\n",
        "**K-fold validation**\n",
        "\n",
        "With this approach, you split your data into K partitions of equal size. For each parti- tion i, train a model on the remaining K 1 partitions, and evaluate it on partition i. - Your final score is then the averages of the K scores obtained. This method is helpful when the performance of your model shows significant variance based on your train- test split. Like holdout validation, this method doesn't exempt you from using a dis- tinct validation set for model calibration.\n",
        "\n",
        "\n",
        "**Iterated K-fold validation with shuffling**\n",
        "\n",
        "This one is for situations in which you have relatively little data available and vou need to evaluate your model as precisely as possible. I've found it to be extremely elpful in Kaggle competitions. It consists of applying K-fold validation multiple times, huffling the data every time before splitting it K ways. The final score is the avera of the scores obtained at each run of K-fold validation. Note that you end up trai ng and evaluating PK models (where P is the number of iterations you use), which can be very expensive.\n",
        "**Beating a common-sense baseline**\n",
        "\n",
        "**Things to keep in mind about model evaluation**\n",
        "\n",
        "#Improving model fit\n",
        "\n",
        "To achieve the perfect fit, you must first overfit. Since you don't know in advance where the boundary lies, you must cross it to find it. Thus, your initial goal as you start working on a problem is to achieve a model that shows some generalization power and that is able to overfit. Once you have such a model, you'll focus on refining gener- alization by fighting overfitting.\n",
        "\n",
        "There are three common problems you'll encounter at this stage:\n",
        "\n",
        "1. Training doesn't get started: your training loss doesn't go down over time.  2. Training gets started just fine, but your model doesn't meaningfully generalize: you can't beat the common-sense baseline you set.\n",
        "3. Training and validation loss both go down over time, and you can beat your baseline, but you don't seem to be able to overfit, which indicates you're still underfitting.\n",
        "\n",
        "**Tuning key gradient descent parameters**\n",
        "\n",
        "Sometimes training doesn't get started, or it stalls too early. Your loss is stuck. This is always something you can overcome: remember that you can fit a model to random data\n",
        "When this happens, it's always a problem with the configuration of the gradient descent process: your choice of optimizer, the distribution of initial values in the weights of your model, your learning rate, or your batch size.\n",
        "\n",
        "**Training a MNIST model with an incorrectly high learning rate**\n"
      ],
      "metadata": {
        "id": "SrdcbdY5BH3b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-sg6NISazskq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17821c4b-c221-435d-da52-02de75b5441f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 643.0837 - accuracy: 0.3102 - val_loss: 2.6938 - val_accuracy: 0.2229\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.6429 - accuracy: 0.2087 - val_loss: 2.2492 - val_accuracy: 0.1655\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 9s 24ms/step - loss: 2.4048 - accuracy: 0.1775 - val_loss: 2.1990 - val_accuracy: 0.1957\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 9s 24ms/step - loss: 2.3351 - accuracy: 0.1840 - val_loss: 2.1904 - val_accuracy: 0.1804\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 2.4278 - accuracy: 0.1662 - val_loss: 2.3166 - val_accuracy: 0.1479\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 2.4642 - accuracy: 0.1763 - val_loss: 2.3737 - val_accuracy: 0.1957\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 2.3306 - accuracy: 0.1744 - val_loss: 2.3254 - val_accuracy: 0.1558\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 2.2515 - accuracy: 0.1836 - val_loss: 2.1365 - val_accuracy: 0.1746\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 2.2684 - accuracy: 0.1743 - val_loss: 2.1242 - val_accuracy: 0.1819\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 2.3666 - accuracy: 0.1859 - val_loss: 2.2953 - val_accuracy: 0.1812\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdeb1a93550>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "(train_images, train_labels), _ = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype(\"float32\") / 255\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(optimizer=keras.optimizers.RMSprop(1.),\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(train_images, train_labels,\n",
        "          epochs=10,\n",
        "          batch_size=128,\n",
        "          validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model quickly reaches a training and validation accuracy in the 30%-40% range but cannot get past that. Let's try to lower the learning rate to a more reasonable value of 1e-2."
      ],
      "metadata": {
        "id": "V16RPIEWJCzb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The same model with a more appropriate learning rate**"
      ],
      "metadata": {
        "id": "1bvPxbvBCVKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(optimizer=keras.optimizers.RMSprop(1e-2),\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(train_images, train_labels,\n",
        "          epochs=10,\n",
        "          batch_size=128,\n",
        "          validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDj8SkBGCbS9",
        "outputId": "11042fc8-210d-49be-fe40-b9c7a900d450"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "375/375 [==============================] - 5s 12ms/step - loss: 0.3764 - accuracy: 0.9102 - val_loss: 0.1416 - val_accuracy: 0.9588\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 0.1280 - accuracy: 0.9646 - val_loss: 0.1202 - val_accuracy: 0.9694\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.0976 - accuracy: 0.9739 - val_loss: 0.1410 - val_accuracy: 0.9673\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 4s 11ms/step - loss: 0.0772 - accuracy: 0.9787 - val_loss: 0.1426 - val_accuracy: 0.9723\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 5s 14ms/step - loss: 0.0672 - accuracy: 0.9829 - val_loss: 0.1619 - val_accuracy: 0.9710\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.0603 - accuracy: 0.9849 - val_loss: 0.1596 - val_accuracy: 0.9732\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.0474 - accuracy: 0.9883 - val_loss: 0.1666 - val_accuracy: 0.9758\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 5s 13ms/step - loss: 0.0496 - accuracy: 0.9888 - val_loss: 0.2076 - val_accuracy: 0.9722\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.0389 - accuracy: 0.9908 - val_loss: 0.2004 - val_accuracy: 0.9754\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.0368 - accuracy: 0.9911 - val_loss: 0.1968 - val_accuracy: 0.9742\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdeb19eb910>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model is now able to train.\n",
        "\n",
        "If you find yourself in a similar situation, try\n",
        "\n",
        "Lowering or increasing the learning rate. A learning rate that is too high may lead to updates that vastly overshoot a proper fit, like in the preceding example, and a learning rate that is too low may make training so slow that it appears to stall.\n",
        "\n",
        " Increasing the batch size. A batch with more samples will lead to gradients that\n",
        "\n",
        "are more informative and less noisy (lower variance).\n"
      ],
      "metadata": {
        "id": "hN5VqTDAJmzH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Leveraging better architecture priors\n",
        "\n",
        "**Increasing model capacity**\n",
        "\n",
        "**A simple logistic regression on MNIST**"
      ],
      "metadata": {
        "id": "o0ocEvFzChPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([layers.Dense(10, activation=\"softmax\")])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_small_model = model.fit(\n",
        "    train_images, train_labels,\n",
        "    epochs=20,\n",
        "    batch_size=128,\n",
        "    validation_split=0.2)"
      ],
      "metadata": {
        "id": "nNk6NcLKCpha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "val_loss = history_small_model.history[\"val_loss\"]\n",
        "epochs = range(1, 21)\n",
        "plt.plot(epochs, val_loss, \"b--\",\n",
        "         label=\"Validation loss\")\n",
        "plt.title(\"Effect of insufficient model capacity on validation loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "k1hlpShLCxts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(96, activation=\"relu\"),\n",
        "    layers.Dense(96, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\"),\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_large_model = model.fit(\n",
        "    train_images, train_labels,\n",
        "    epochs=20,\n",
        "    batch_size=128,\n",
        "    validation_split=0.2)"
      ],
      "metadata": {
        "id": "uutjNaxzCyZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Improving generalization\n",
        "\n",
        "** Dataset curation**\n",
        "\n",
        "**Feature engineering**\n",
        "\n",
        "**Using early stopping**\n",
        "\n",
        "**Regularizing your model**\n",
        "\n",
        "**Reducing the network's size**\n",
        "\n",
        "Original model"
      ],
      "metadata": {
        "id": "cxRBbOiVC3hP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rom tensorflow.keras.datasets import imdb\n",
        "(train_data, train_labels), _ = imdb.load_data(num_words=10000)\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.\n",
        "    return results\n",
        "train_data = vectorize_sequences(train_data)\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_original = model.fit(train_data, train_labels,\n",
        "                             epochs=20, batch_size=512, validation_split=0.4)"
      ],
      "metadata": {
        "id": "M6nnfzQVDZhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Version of the model with lower capacity**"
      ],
      "metadata": {
        "id": "aJawDHWKDaMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(4, activation=\"relu\"),\n",
        "    layers.Dense(4, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_smaller_model = model.fit(\n",
        "    train_data, train_labels,\n",
        "    epochs=20, batch_size=512, validation_split=0.4)"
      ],
      "metadata": {
        "id": "hnqOecygDfDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Adding weight regularization\n",
        "\n",
        "**Adding L2 weight regularization to the model**"
      ],
      "metadata": {
        "id": "RsNyS-98D_oK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import regularizers\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(16,\n",
        "                 kernel_regularizer=regularizers.l2(0.002),\n",
        "                 activation=\"relu\"),\n",
        "    layers.Dense(16,\n",
        "                 kernel_regularizer=regularizers.l2(0.002),\n",
        "                 activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_l2_reg = model.fit(\n",
        "    train_data, train_labels,\n",
        "    epochs=20, batch_size=512, validation_split=0.4)"
      ],
      "metadata": {
        "id": "Q68pFOgTDi02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Different weight regularizers available in Keras**"
      ],
      "metadata": {
        "id": "q_DAiF0_D2_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import regularizers\n",
        "regularizers.l1(0.001)\n",
        "regularizers.l1_l2(l1=0.001, l2=0.001)"
      ],
      "metadata": {
        "id": "qY6-8aEtDmQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding dropout\n",
        "\n",
        "**Adding dropout to the IMDB model**"
      ],
      "metadata": {
        "id": "NNgewO8ZDumv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "history_dropout = model.fit(\n",
        "    train_data, train_labels,\n",
        "    epochs=20, batch_size=512, validation_split=0.4)"
      ],
      "metadata": {
        "id": "uJTI7UKGDpt4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNS7SWv97x40HLXk9pfYBxQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}